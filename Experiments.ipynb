{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from nltk.corpus import stopwords \n",
    "import os\n",
    "\n",
    "def removeStopWords(wordList):\n",
    "    return [word for word in wordList if word not in stopwords.words('english')]\n",
    "\n",
    "# DO NOT USE\n",
    "def calcCosSimOld(aMat,bVec):\n",
    "    # Calculate cosine simularity\n",
    "    a = np.sum(aMat,axis=0)/aMat.shape[0]\n",
    "    b = bVec.copy()\n",
    "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def calcCosSim(a,b):\n",
    "    # Calculate cosine simularity\n",
    "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def removeStem(sentence):\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(sentence)\n",
    "    tmpStr = ''\n",
    "    for w in words:\n",
    "        tmpStr += ps.stem(w) + ' '\n",
    "    return tmpStr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I ca n't believ these peopl termin my account  \", 'My account got termin for no reason when I wa work with them . A complet wast of my time !  ', \"I ca n't believ thi compani stole my patent and violat my intellectu properti right ! ! !  \", 'My access to the site got termin without an explain . what a wast of my time ! ! !  ']\n"
     ]
    }
   ],
   "source": [
    "rootPath = './company0/'\n",
    "complaintSubPath = 'complaint/'\n",
    "\n",
    "#contractPath = rootPath + '/termService/' + '0.txt'\n",
    "#contractPath = rootPath + '/termService/' + 'related.txt'\n",
    "contractPath = rootPath + '/termService/' + 'unrelated.txt'\n",
    "\n",
    "contractTxt = open(contractPath, encoding=\"utf8\", errors='ignore').read()\n",
    "contractVec = removeStopWords([removeStem(contractTxt)])\n",
    "\n",
    "vec = CountVectorizer()\n",
    "contractFreq = vec.fit_transform(contractVec)\n",
    "\n",
    "\n",
    "compList = []\n",
    "\n",
    "# Used for removing stem from words\n",
    "for cFilePath in os.listdir(rootPath + complaintSubPath):\n",
    "    cFilePath = rootPath + complaintSubPath + cFilePath\n",
    "    cFileTxt = open(cFilePath,'r').read()\n",
    "\n",
    "    cFileTxt = removeStem(cFileTxt)\n",
    "    \n",
    "    compList.append(cFileTxt + ' ')\n",
    "    \n",
    "print(compList)\n",
    "compList = [''.join(str(v) for v in compList)]  # We are combining all complaints into one\n",
    "complantCnt = CountVectorizer()\n",
    "a = complantCnt.fit_transform(compList)\n",
    "#print(contractVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['access',\n",
       " 'account',\n",
       " 'an',\n",
       " 'and',\n",
       " 'believ',\n",
       " 'ca',\n",
       " 'compani',\n",
       " 'complet',\n",
       " 'explain',\n",
       " 'for',\n",
       " 'got',\n",
       " 'intellectu',\n",
       " 'my',\n",
       " 'no',\n",
       " 'of',\n",
       " 'patent',\n",
       " 'peopl',\n",
       " 'properti',\n",
       " 'reason',\n",
       " 'right',\n",
       " 'site',\n",
       " 'stole',\n",
       " 'termin',\n",
       " 'the',\n",
       " 'them',\n",
       " 'these',\n",
       " 'thi',\n",
       " 'time',\n",
       " 'to',\n",
       " 'violat',\n",
       " 'wa',\n",
       " 'wast',\n",
       " 'what',\n",
       " 'when',\n",
       " 'with',\n",
       " 'without',\n",
       " 'work']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complantCnt.get_feature_names()\n",
    "#complantCnt.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1782785045546807"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaintDf = pd.DataFrame(a.toarray(),columns=complantCnt.get_feature_names())\n",
    "contractDf = pd.DataFrame(contractFreq.toarray(),columns=vec.get_feature_names())\n",
    "#contractDf\n",
    "combinedDf = pd.concat([complaintDf, contractDf],sort=False).fillna(value=0.0)\n",
    "complainVec = combinedDf.iloc[0].values\n",
    "contractVec = combinedDf.iloc[1].values\n",
    "\n",
    "calcCosSim(complainVec,contractVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = open(rootPath + '/termService/0.txt', encoding=\"utf8\", errors='ignore').read()\n",
    "tmpList = tmp.split(\"\\n\")\n",
    "len(tmpList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
